import ast
import inspect
import os
import re
from string import Template
from typing import List, Callable, Tuple

import click
from dotenv import load_dotenv
from openai import OpenAI
from langchain_ollama import ChatOllama

import platform

from prompt_template import react_system_prompt_template

load_dotenv()

class ReActAgent:
    def __init__(self, tools: List[Callable], model: str, project_directory: str):
        self.tools = { func.__name__: func for func in tools }
        self.model = model
        self.project_directory = project_directory

        model_source = os.getenv('model_source', 'gpt-4o')
        if model_source == "gpt-4o":
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=ReActAgent.get_api_key(),
            )
        else:
            print(f"\n\nğŸ’­ TChatOllama\n")
            self.llm = ChatOllama(
                base_url="http://localhost:11434",
                model="mistral:latest",
            )
            



    def run(self, user_input: str):
        messages = [
            {"role": "system", "content": self.render_system_prompt(react_system_prompt_template)},
            {"role": "user", "content": f"<question>{user_input}</question>"}
        ]
        
        while True:
            # è¯·æ±‚æ¨¡å‹
            content = self.call_model(messages)
            
            # æå–æ‰€æœ‰thought-actionå¯¹
            thought_actions = re.findall(r"<thought>(.*?)</thought>\s*<action>(.*?)</action>", content, re.DOTALL)
            
            # å¤„ç†æ¯ä¸ªthought-actionå¯¹
            for thought, action in thought_actions:
                print(f"\n\nğŸ’­ Thought: {thought.strip()}")
                
                tool_name, args = self.parse_action(action.strip())
                print(f"\n\nğŸ”§ Action: {tool_name}({', '.join(args)})")
                
                # è¯¢é—®ç”¨æˆ·ç¡®è®¤
                should_continue = input("\n\næ˜¯å¦ç»§ç»­ï¼Ÿï¼ˆY/Nï¼‰") if tool_name == "run_terminal_command" else "y"
                if should_continue.lower() != 'y':
                    print("\n\næ“ä½œå·²å–æ¶ˆã€‚")
                    return "æ“ä½œè¢«ç”¨æˆ·å–æ¶ˆ"
                
                try:
                    observation = self.tools[tool_name](*args)
                except Exception as e:
                    observation = f"å·¥å…·æ‰§è¡Œé”™è¯¯ï¼š{str(e)}"
                
                print(f"\n\nğŸ” Observationï¼š{observation}")
                messages.append({"role": "user", "content": f"<observation>{observation}</observation>"})
            
            # æ£€æŸ¥æ˜¯å¦æœ‰final_answer
            final_match = re.search(r"<thought>(.*?)</thought>\s*<final_answer>(.*?)</final_answer>", content, re.DOTALL)
            if final_match:
                thought = final_match.group(1)
                final_answer = final_match.group(2)
                print(f"\n\nğŸ’­ Thought: {thought.strip()}")
                return final_answer.strip()
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•thought-actionæˆ–final_answerï¼ŒæŠ¥é”™
            if not thought_actions and not final_match:
                raise RuntimeError("æ¨¡å‹è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘<thought>-<action>å¯¹æˆ–<final_answer>")


    def get_tool_list(self) -> str:
        """ç”Ÿæˆå·¥å…·åˆ—è¡¨å­—ç¬¦ä¸²ï¼ŒåŒ…å«å‡½æ•°ç­¾åå’Œç®€è¦è¯´æ˜"""
        tool_descriptions = []
        for func in self.tools.values():
            name = func.__name__
            signature = str(inspect.signature(func))
            doc = inspect.getdoc(func)
            tool_descriptions.append(f"- {name}{signature}: {doc}")
        return "\n".join(tool_descriptions)

    def render_system_prompt(self, system_prompt_template: str) -> str:
        """æ¸²æŸ“ç³»ç»Ÿæç¤ºæ¨¡æ¿ï¼Œæ›¿æ¢å˜é‡"""
        tool_list = self.get_tool_list()
        file_list = ", ".join(
            os.path.abspath(os.path.join(self.project_directory, f))
            for f in os.listdir(self.project_directory)
        )
        return Template(system_prompt_template).substitute(
            operating_system=self.get_operating_system_name(),
            tool_list=tool_list,
            file_list=file_list
        )

    @staticmethod
    def get_api_key() -> str:
        """Load the API key from an environment variable."""
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            raise ValueError("æœªæ‰¾åˆ° OPENROUTER_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®ã€‚")
        return api_key
    
    def convert_messages(self,messages, to_dict=True):
        """
        Convert between message formats:
        - Dict format: [{"role": x, "content": y}, ...]
        - Tuple format: [(x, y), ...]
        
        Args:
            messages: List of messages in either format
            to_dict: If True, converts to dict format, else to tuple format
        
        Returns:
            List of messages in the converted format
        """
        converted = []
        
        for msg in messages:
            if to_dict:
                # Convert from tuple to dict format
                if isinstance(msg, tuple):
                    role, content = msg
                    converted.append({"role": role, "content": content})
                else:
                    converted.append(msg)  # already in dict format
            else:
                # Convert from dict to tuple format
                if isinstance(msg, dict):
                    converted.append((msg["role"], msg["content"]))
                else:
                    converted.append(msg)  # already in tuple format
                    
        return converted

    
    def call_model(self, messages):
        print("\n\næ­£åœ¨è¯·æ±‚æ¨¡å‹ï¼Œè¯·ç¨ç­‰...")

        model_source = os.getenv('model_source', 'gpt-4o')
        if model_source == "gpt-4o":
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
            )
            content = response.choices[0].message.content
            messages.append({"role": "assistant", "content": content})
            return content   
        else:
            tup_messages = self.convert_messages(messages,to_dict=False)
            response = self.llm.invoke(tup_messages)
           
            # Handle response.content based on type
            if isinstance(response.content, str):
                content = response.content
            elif isinstance(response.content, list):
                # Concatenate all string parts (ignore dicts for now)
                content = ''.join(
                    part if isinstance(part, str) else str(part)
                    for part in response.content
                )
            else:
                raise ValueError("Unsupported content type returned from model")

            # Append model reply to the message history
            messages.append({"role": "assistant", "content": content})

            return content  # return just the model's response text



    def parse_action(self, code_str: str) -> Tuple[str, List[str]]:
        match = re.match(r'(\w+)\((.*)\)', code_str, re.DOTALL)
        if not match:
            raise ValueError("Invalid function call syntax")

        func_name = match.group(1)
        args_str = match.group(2).strip()

        # æ‰‹åŠ¨è§£æå‚æ•°ï¼Œç‰¹åˆ«å¤„ç†åŒ…å«å¤šè¡Œå†…å®¹çš„å­—ç¬¦ä¸²
        args = []
        current_arg = ""
        in_string = False
        string_char = None
        i = 0
        paren_depth = 0
        
        while i < len(args_str):
            char = args_str[i]
            
            if not in_string:
                if char in ['"', "'"]:
                    in_string = True
                    string_char = char
                    current_arg += char
                elif char == '(':
                    paren_depth += 1
                    current_arg += char
                elif char == ')':
                    paren_depth -= 1
                    current_arg += char
                elif char == ',' and paren_depth == 0:
                    # é‡åˆ°é¡¶å±‚é€—å·ï¼Œç»“æŸå½“å‰å‚æ•°
                    args.append(self._parse_single_arg(current_arg.strip()))
                    current_arg = ""
                else:
                    current_arg += char
            else:
                current_arg += char
                if char == string_char and (i == 0 or args_str[i-1] != '\\'):
                    in_string = False
                    string_char = None
            
            i += 1
        
        # æ·»åŠ æœ€åä¸€ä¸ªå‚æ•°
        if current_arg.strip():
            args.append(self._parse_single_arg(current_arg.strip()))
        
        return func_name, args
    
    def _parse_single_arg(self, arg_str: str):
        """è§£æå•ä¸ªå‚æ•°"""
        arg_str = arg_str.strip()
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²å­—é¢é‡
        if (arg_str.startswith('"') and arg_str.endswith('"')) or \
           (arg_str.startswith("'") and arg_str.endswith("'")):
            # ç§»é™¤å¤–å±‚å¼•å·å¹¶å¤„ç†è½¬ä¹‰å­—ç¬¦
            inner_str = arg_str[1:-1]
            # å¤„ç†å¸¸è§çš„è½¬ä¹‰å­—ç¬¦
            inner_str = inner_str.replace('\\"', '"').replace("\\'", "'")
            inner_str = inner_str.replace('\\n', '\n').replace('\\t', '\t')
            inner_str = inner_str.replace('\\r', '\r').replace('\\\\', '\\')
            return inner_str
        
        # å°è¯•ä½¿ç”¨ ast.literal_eval è§£æå…¶ä»–ç±»å‹
        try:
            return ast.literal_eval(arg_str)
        except (SyntaxError, ValueError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
            return arg_str

    def get_operating_system_name(self):
        os_map = {
            "Darwin": "macOS",
            "Windows": "Windows",
            "Linux": "Linux"
        }

        return os_map.get(platform.system(), "Unknown")
        
# react_agent.py
def react_agent_process(user_input: str) -> str:
    # Simulate intelligent response
    return f"ä½ è¯´çš„æ˜¯ï¼š{user_input}ï¼Œè¿™æ˜¯æˆ‘æ ¹æ®ä½ çš„è¯­éŸ³åšå‡ºçš„å›åº”ã€‚"



def read_file(file_path):
    """ç”¨äºè¯»å–æ–‡ä»¶å†…å®¹"""
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()

def write_to_file(file_path, content):
    """å°†æŒ‡å®šå†…å®¹å†™å…¥æŒ‡å®šæ–‡ä»¶"""
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(content.replace("\\n", "\n"))
    return "å†™å…¥æˆåŠŸ"

def run_terminal_command(command):
    """ç”¨äºæ‰§è¡Œç»ˆç«¯å‘½ä»¤"""
    import subprocess
    run_result = subprocess.run(command, shell=True, capture_output=True, text=True)
    return "æ‰§è¡ŒæˆåŠŸ" if run_result.returncode == 0 else run_result.stderr

@click.command()
@click.argument('project_directory',
                type=click.Path(exists=True, file_okay=False, dir_okay=True))
@click.argument('task', required=False)  # Make task optional
def main(project_directory, task):
    project_dir = os.path.abspath(project_directory)

    tools = [read_file, write_to_file, run_terminal_command]
    model_name=os.getenv("TOOL_LLM_NAME", "mistral:latest")
    agent = ReActAgent(tools=tools, model=model_name, project_directory=project_dir)

    # If task is provided via command line, use it; otherwise prompt for input
    if not task:
        task = input("è¯·è¾“å…¥ä»»åŠ¡ï¼š")
    final_answer = agent.run(task)
    
    print(f"\n\nâœ… Final Answerï¼š{final_answer}")

if __name__ == "__main__":
    main()
